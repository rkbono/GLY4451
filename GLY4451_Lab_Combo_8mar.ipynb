{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2cad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image \n",
    "\n",
    "import datetime as dt\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805afcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "    !git clone https://github.com/rkbono/GLY4451.git\n",
    "    !pip install cartopy\n",
    "    fpath = './GLY4451/'\n",
    "else:\n",
    "    print('Not running on CoLab')\n",
    "    fpath = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e25bea7",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "1. Intro to grids and np.meshgrid\n",
    "1. Contour plots\n",
    "1. Linear regresion (by hand)\n",
    "1. Linear regression (with scipy)\n",
    "1. Quick bootstrap\n",
    "1. Quick monte carlo\n",
    "1. Cluster analysis\n",
    "1. Searching for global minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790e8a4a",
   "metadata": {},
   "source": [
    "# Grids and np.meshgrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14091d",
   "metadata": {},
   "source": [
    "Numpy meshgrid is a tool for numeric data manipulation in Python.\n",
    "\n",
    "We use Numpy meshgrid to create a rectangular grid of x and y values.\n",
    "\n",
    "More specifically, meshgrid creates coordinate values that enable us to construct a rectangular grid of values.\n",
    "\n",
    "It does this in a somewhat roundabout way.\n",
    "\n",
    "As inputs to the function, we provide 1-dimensional arrays with numeric values. These numeric values will be the coordinates of the new “meshgrid.”\n",
    "\n",
    "The output of np.meshgrid is a set of Numpy arrays that contain the coordinates of this new grid space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac6fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(fpath+'Figures/meshgrid2d.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01c4c55",
   "metadata": {},
   "source": [
    "# Contour plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da9a9c",
   "metadata": {},
   "source": [
    "A contour line or isoline of a function of two variables is a curve along which the function has a constant value.\n",
    "\n",
    "It is a cross-section of the three-dimensional graph of the function f(x, y) parallel to the x, y plane.\n",
    "\n",
    "A contour plot is appropriate if you want to see how value Z changes as a function of two inputs X and Y, such that Z = f(X,Y). A contour line or isoline of a function of two variables is a curve along which the function has a constant value.\n",
    "\n",
    "The independent variables x and y are usually restricted to a regular grid called meshgrid. The numpy.meshgrid creates a rectangular grid out of an array of x values and an array of y values.\n",
    "\n",
    "Matplotlib API contains contour() and contourf() functions that draw contour lines and filled contours, respectively. Both functions need three parameters x,y and z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda642d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlist = np.linspace(-3.0, 3.0, 100)\n",
    "ylist = np.linspace(-3.0, 3.0, 100)\n",
    "X, Y = np.meshgrid(xlist, ylist)\n",
    "Z = np.sqrt(X**2 + Y**2)\n",
    "fig,ax=plt.subplots(1,1)\n",
    "cp = ax.contourf(X, Y, Z)\n",
    "fig.colorbar(cp) # Add a colorbar to a plot\n",
    "ax.set_title('Filled Contours Plot')\n",
    "ax.set_xlabel('x (cm)')\n",
    "ax.set_ylabel('y (cm)')\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad79ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlist = np.linspace(-3.0, 3.0, 100)\n",
    "ylist = np.linspace(-3.0, 3.0, 100)\n",
    "X, Y = np.meshgrid(xlist, ylist)\n",
    "Z = np.sqrt(X**2 + Y**2)\n",
    "fig,ax=plt.subplots(1,1)\n",
    "cp = ax.contour(X, Y, Z)\n",
    "ax.set_title('Filled Contours Plot')\n",
    "ax.set_xlabel('x (cm)')\n",
    "ax.set_ylabel('y (cm)')\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc30a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlist = np.linspace(-3.0, 3.0, 100)\n",
    "ylist = np.linspace(-3.0, 3.0, 100)\n",
    "X, Y = np.meshgrid(xlist, ylist)\n",
    "Z = np.sqrt(X**2 + Y**2)\n",
    "fig,ax=plt.subplots(1,1)\n",
    "cp = ax.contourf(X, Y, Z,cmap=plt.cm.turbo,levels=100)\n",
    "ax.contour(X,Y,Z,colors='k')\n",
    "fig.colorbar(cp) # Add a colorbar to a plot\n",
    "ax.set_title('Filled Contours Plot')\n",
    "ax.set_xlabel('x (cm)')\n",
    "ax.set_ylabel('y (cm)')\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2f7da1",
   "metadata": {},
   "source": [
    "## Challenge:\n",
    "\n",
    "Plot temperature with respect to age and depth for the crust near a spreading ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get temp given depth, age, initial temp and diffusitivity\n",
    "def halfspace_temp(z,t,ta,ka):\n",
    "    \n",
    "    return ta*sp.special.erf(z/(2*np.sqrt(ka*t)))\n",
    "\n",
    "# age from myr to seconds\n",
    "fMyr = lambda t: dt.timedelta(weeks=52).total_seconds()*1e6*t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc9a325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "ka = 1e-6 # diffusivity\n",
    "t0 = 1300 # initial temp\n",
    "\n",
    "# initial vector of ages\n",
    "tmyr = np.arange(0,100.1,1)\n",
    "\n",
    "# initial vector of depths\n",
    "dz = np.arange(0,150e3,1e3)\n",
    "\n",
    "# colormap\n",
    "cmap = plt.cm.magma\n",
    "\n",
    "# levels for contours\n",
    "lev = np.arange(0,1300+1e-5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(fpath+'Figures/heat_contourf.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e061aa",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "## By \"hand\"\n",
    "\n",
    "Let's put into practice what we talked about on Monday. Using numpy, let's implement our own version of a linear regression.\n",
    "\n",
    "Recall:\n",
    "\n",
    "$\\beta = (X^{T}X)^{-1}X^{T}y$\n",
    "\n",
    "So for a given set of observations **y** and independent regressor **x** we'd like to fit model parameters $\\beta$. \n",
    "\n",
    "Let's work with just a simple curve (degree 2 polynomial) with the form:\n",
    "\n",
    "$y = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^2$\n",
    "\n",
    "This makes **X** our design matrix easy to setup. For each observation $y_i$, **X** will have a row containing [1, $x_i$] corresponding to the two model parameters in $\\beta$. \n",
    "\n",
    "We can use **np.linalg** package to perform linear algebra operations as we solve for $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some model parameters to find\n",
    "beta_true = [1, 0.5,0.25]\n",
    "\n",
    "# and a quick line function\n",
    "fxy = lambda x: beta_true[0]+beta_true[1]*x+beta_true[2]*x**2\n",
    "xv = np.linspace(0,20,100) # and simple line vector\n",
    "\n",
    "# Let's generate some sample data with noise\n",
    "xobs = np.random.uniform(0,20,size=30)\n",
    "yobs = fxy(xobs)\n",
    "\n",
    "# and take a look at the data\n",
    "plt.plot(xobs,yobs,'ok',label='obs')\n",
    "plt.plot(xv,fxy(xv),'-',label='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2bbd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets set up our design matrix\n",
    "X = np.vstack([np.ones_like(xobs),xobs,xobs**2]).T # added transpose\n",
    "\n",
    "# and regress!\n",
    "norm_matrix = np.linalg.inv(np.dot(X.T,X))\n",
    "beta_guess = np.linalg.multi_dot([norm_matrix,X.T,yobs.T])\n",
    "print(beta_guess)\n",
    "\n",
    "beta_regress_np = np.linalg.lstsq(X,yobs,rcond=None)\n",
    "print(beta_regress_np[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfbf39d",
   "metadata": {},
   "source": [
    "## Add some error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced3993",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1397)\n",
    "\n",
    "# Let's generate some sample data with noise\n",
    "xobs = np.random.uniform(0,20,size=30)\n",
    "yobs = fxy(xobs)+np.random.normal(scale=5,size=xobs.shape) # random term adds Gaussian noise\n",
    "\n",
    "# and take a look at the data\n",
    "plt.plot(xobs,yobs,'ok',label='obs')\n",
    "plt.plot(xv,fxy(xv),'-',label='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a49cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets set up our design matrix\n",
    "X = np.vstack([np.ones_like(xobs),xobs,xobs**2]).T # added transpose\n",
    "\n",
    "# and regress!\n",
    "norm_matrix = np.linalg.inv(np.dot(X.T,X))\n",
    "beta_guess = np.linalg.multi_dot([norm_matrix,X.T,yobs.T])\n",
    "print(beta_guess)\n",
    "\n",
    "beta_regress_np = np.linalg.lstsq(X,yobs,rcond=None)\n",
    "print(beta_regress_np[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f676d",
   "metadata": {},
   "source": [
    "## Calculate $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11dcee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssr = np.sum([(yi-(beta_guess[0]+beta_guess[1]*xi+beta_guess[2]*xi**2))**2 for yi,xi in zip(yobs,xobs)])\n",
    "print(ssr,beta_regress_np[1][0])\n",
    "\n",
    "sst = np.sum((yobs-np.mean(yobs))**2)\n",
    "\n",
    "r2 = 1-(ssr/sst)\n",
    "\n",
    "print('R^2 = %.3f'%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901a591",
   "metadata": {},
   "source": [
    "## Plot fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdbae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xobs,yobs,'ok',label='obs')\n",
    "plt.plot(xv,fxy(xv),'-',label='true')\n",
    "plt.plot(xv,[(beta_guess[0]+beta_guess[1]*xi+beta_guess[2]*xi**2) for xi in xv],'-',label='fit, $R^2$: '+'%.3f'%r2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a7d01c",
   "metadata": {},
   "source": [
    "# Bootstrapping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ec8c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets set up our design matrix\n",
    "X = np.vstack([np.ones_like(xobs),xobs,xobs**2]).T # added transpose\n",
    "\n",
    "# lets functionalize our regression\n",
    "freg = lambda X,y: np.linalg.multi_dot([np.linalg.inv(np.dot(X.T,X)),X.T,y.T])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d330d42",
   "metadata": {},
   "source": [
    "### Bootstrapping consists of the following steps:\n",
    "1. Define a desired statistic(s) and a collector to hold the results\n",
    "1. Set up a for loop to interate the desired number of realizations (ndraw >= 2500)\n",
    "1. In each loop, draw with replacement from the observations to generate a synthetic dataset\n",
    "1. With the synthetic dataset, perform statistics and collect result\n",
    "1. After all fits are done, examine the resulting stats\n",
    "1. ???\n",
    "1. Profit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafdc12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndraw = 10000\n",
    "\n",
    "res = []\n",
    "\n",
    "for ii in range(ndraw):\n",
    "    ridx = np.random.randint(0,X.shape[0],size=X.shape[0])\n",
    "    Xt = X[ridx,:]\n",
    "    yt = yobs[ridx]\n",
    "    res.append(freg(Xt,yt))\n",
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352b4c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,4))\n",
    "ax = fig.subplots(1,3)\n",
    "\n",
    "for ii in range(3):\n",
    "    ax[ii].hist(res[:,ii],bins=100)\n",
    "    ax[ii].axvline(beta_true[ii],color='red',linewidth=2,linestyle='--',label='True')\n",
    "    [ax[ii].axvline(pp,color='k') for pp in np.percentile(res[:,ii],[2.5,50,97.5])]\n",
    "    \n",
    "    ax[ii].set_title(r'$\\beta_{%d}$'%ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd851b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.subplots(1,1)\n",
    "\n",
    "ax.plot(xobs,yobs,'ob',mec='w',zorder=100)\n",
    "ax.plot(xv,fxy(xv),'-r',label='True',zorder=10)\n",
    "\n",
    "for rr in res[::10]:\n",
    "    ax.plot(xv,(rr[0]+rr[1]*xv+rr[2]*xv**2),'-',color='grey',linewidth=0.5,alpha=0.1,zorder=0)\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80507941",
   "metadata": {},
   "source": [
    "# Quick Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f89add",
   "metadata": {},
   "source": [
    "## Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrng = [0,1]\n",
    "yrng = [0,1]\n",
    "\n",
    "fcirc = lambda x,y: True if (x**2 + y**2 <= 1) else False\n",
    "\n",
    "rnd = np.random.random(size=[int(1e3),2])\n",
    "counts = np.array([[x[0],x[1],fcirc(x[0],x[1])] for x in rnd])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.subplots(1,1)\n",
    "\n",
    "ax.plot(counts[counts[:,2]==1,0],counts[counts[:,2]==1,1],'.b')\n",
    "ax.plot(counts[counts[:,2]==0,0],counts[counts[:,2]==0,1],'.r')\n",
    "\n",
    "ax.plot(np.cos(np.linspace(0,np.pi/2,100)),np.sin(np.linspace(0,np.pi/2,100)),'-k')\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(xrng)\n",
    "ax.set_ylim(yrng)\n",
    "\n",
    "print(4*np.sum(counts[:,2])/counts.shape[0],np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd04000f",
   "metadata": {},
   "source": [
    "## Challenge - convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509fd3d",
   "metadata": {},
   "source": [
    "Goal: Estimate how many Mone Carlo realizations are needed to get an accurate estimate of pi. Consider how close is close enough? What's an efficient way to explore the question? How variable is the estimate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb8e5a0",
   "metadata": {},
   "source": [
    "## Challenge - Monte Carlo Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740ce63b",
   "metadata": {},
   "source": [
    "Goal: estimate the geotherm temperature at 20 km depth given surface heat flow and internal heat generation. But both observations are means w/ uncertainty based on several measurements that have been averaged together, so your temperature estimate should include that uncertainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting temp from equilibrium geotherm and q0 at the surface\n",
    "def geotherm_surf(z,q,a,k):\n",
    "    \"\"\"\n",
    "    returns temp (degC) given depth z (m), surf heat flow q, internal heat a and conductivity k\n",
    "    \"\"\"\n",
    "    return -(a/(2*k))*z**2 + q/k*z\n",
    "\n",
    "# constants\n",
    "k = 2.5 # conductivity\n",
    "q0 = {'mean':0.058,'std':0.01}\n",
    "A = {'mean':1.25e-6,'std':0.250e-6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc64e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at geotherm assuming mean values\n",
    "zz = np.linspace(0,30e3,100)\n",
    "\n",
    "tz = geotherm_surf(zz,q0['mean'],A['mean'],k)\n",
    "\n",
    "plt.plot(tz,zz/1e3,'-r')\n",
    "plt.ylim([30,0])\n",
    "plt.xlabel('Temp (°C)')\n",
    "plt.ylabel('Depth (km)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc3cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(fpath+'Figures/q0_a_montecarlo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(fpath+'Figures/geotherm_mc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8665e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(fpath+'Figures/temp_at_20km.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78154f",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "We'll be reproducing an example of using k-means clustering to group a set of structural data on either side of a fold axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4a9663",
   "metadata": {},
   "source": [
    "### The Orocopio Mountains Dataset\n",
    "The dataset poles_data contains a dataset of poles to bedding planes from the Orocopio mountains. We learned about poles to planes in Lecture 22. If a rock is composed of sediments that are layed down flat on top of one another, then we would expect the pole to the plane to be vertical (because the plane itself is horizontal). If instead the plane is tilted, we might expect the pole to the plane to be in some other direction. Let's peek at a data set of poles from bedding planes measured in the  Orocopio Mountains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "poles_data=pd.read_csv(fpath+'Datasets/Orocopio_Poles_Data.csv')\n",
    "poles_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceada95",
   "metadata": {},
   "source": [
    "We can use a modified equal area plot to plot the 'Pole_Az' and 'Pole Plunge' columns on an equal area projection to see what the bedding planes look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc6c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the equal angle function\n",
    "EqualArea = lambda Pl: np.sqrt(2.)*90.*np.sin(np.radians(90.-Pl)/(2.))\n",
    "\n",
    "def plot_equal_area(Azs,Pls,colors='black',cmap='RdBu',alpha=1):\n",
    "    \"\"\"\n",
    "    Plots an Equal Angle plot for data d, colors are a string or list of colors\n",
    "    to be passed to the points in data\n",
    "    Note that this is different to the code in lecture 20 because it uses a\n",
    "    scatter plot.\n",
    "    \n",
    "    Parameters:\n",
    "    ____________\n",
    "        Azs : np.array\n",
    "            Azimuths of poles to planes\n",
    "        Pls : np.array\n",
    "            Plunges of poles to planes\n",
    "            \n",
    "    Returns:\n",
    "    _________\n",
    "        None\n",
    "             \n",
    "    \"\"\"\n",
    "    fig = plt.subplot(111, polar=True) \n",
    "    # set the coordinates (like for rose diagrams)\n",
    "    fig.set_theta_direction(-1) # Reverse direction of degrees (CW)\n",
    "    fig.set_theta_zero_location(\"N\") # Specify 0-degrees as North\n",
    "    # for this we want the full 90 degrees, so set the scale\n",
    "    plt.polar([0],[90]) ## to scale grid\n",
    "    # plot the first direction as a red dot\n",
    "    fig.scatter(np.radians(Azs),(EqualArea(Pls)),c=colors,cmap=cmap,alpha=alpha)\n",
    "    # plot the second direction as a blue square\n",
    "\n",
    "    # make a list of contours to plot\n",
    "    # notice use of list comprehension\n",
    "    # label the azimuths at 20 degree intervals\n",
    "    AzContours=range(0,360,20)\n",
    "    AzLabels=[str(p) for p in AzContours]\n",
    "    plt.thetagrids(AzContours,AzLabels)\n",
    "    # and now the plunges\n",
    "    PlContours=[EqualArea(a) for a in range(10,90,20)] ##don't include center or edge\n",
    "    # make a list of labels\n",
    "    PlLabels=[str(a) for a in range(10,90,20)]\n",
    "    # draw on the plunge contours and label them\n",
    "    plt.rgrids(PlContours,PlLabels)\n",
    "    # label the plot\n",
    "    plt.title('Equal Area Net');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f6c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_equal_area(poles_data.Pole_Az,poles_data.Pole_Plunge,colors='cyan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3d3d53",
   "metadata": {},
   "source": [
    "This is interesting! It seems that there are two 'clusters' with of bedding planes in different directions in this dataset, one to the north-east and one to the south-west. We want a way of separating these two clusters, but first let's think about what causes this. Is there some spatial relationship between where the different directions are found?\n",
    "\n",
    "#### Quiver Plots and **plt.imshow( )**\n",
    "\n",
    "To illustrate this we can use a type of plot known as a 'quiver plot'.  We will learn more about quiver plots in later lectures.  But for now, it draws an arrow with the direction of the plane on a plot. To do this, we need to convert the data from azimuth and plunge to x, y and z. We have the handy function **dir2cart( )** which we already know about.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir2cart(Az,Pl):\n",
    "    \"\"\"\n",
    "    converts polar directions to cartesian coordinates\n",
    "    Inputs: \n",
    "        Dir[Azimuth,Plunge]:  directions in degreess\n",
    "    Output:\n",
    "        [X,Y,Z]: cartesian coordinates\n",
    "    \"\"\"\n",
    "    Az=np.radians(Az)\n",
    "    Pl=np.radians(Pl)\n",
    "    return [np.cos(Az)*np.cos(Pl),np.sin(Az)*np.cos(Pl),np.sin(Pl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d7b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cartesian form of pole vectors\n",
    "u,v,w=dir2cart(poles_data.Pole_Az.values,poles_data.Pole_Plunge.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db4898a",
   "metadata": {},
   "source": [
    "In our coordinate system, $w$ is straight up, so planes with a steeper direction will have a smaller $u$ and $v$ components and a larger $w$ component, and so the arrows on the quiver plot will appear shorter in length.  \n",
    "\n",
    "We will plot the quiver plot on top of a satellite image of the area, using the **plt.imread( )** and **plt.imshow( )** functions in **matplotlib**. These take an image and convert it into a coordinate system we can plot data onto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ebf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(fpath+'Figures/GoogleEarthImage.png') #Reads in our image as a numpy array\n",
    "extent = [-115.7115, -115.6795, 33.5442, 33.5651] #Sets the corners of the image in lat/lon for plotting\n",
    "plt.figure(figsize=(9,13)) #Creates a new figure object to put the image on\n",
    "plt.imshow(img, origin='upper', extent=extent) #Plots the satellite image.;\n",
    "\n",
    "#Now let's plot the quivers onto the image \n",
    "#plt.quiver takes 4 arguments, x and y (locations of arrows), \n",
    "# and u and v (lengths of arrows in u and v directions).  \n",
    "# We can also set the color so we can see the vectors better\n",
    "\n",
    "plt.quiver(poles_data.Lon,poles_data.Lat,u,v,color='cyan');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869f3de4",
   "metadata": {},
   "source": [
    "This plot tells us an interesting story. Along the center of the satellite image runs a linear feature. To the north of this feature, we see that the arrows are pointing to the north-east. To the south-west of this image, the arrows are pointing south-west. What could be the cause of this pattern?\n",
    "\n",
    "One probable cause would be a fold or anticline. For an illustration, see the image below. In an anticline, the horizontal layers are tilted away from the axis of the fold, so that the poles to the plane (arrows) are pointing away from the fold axis (dotted line). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9e595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image('Figures/Fold_Diagram.png',width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d3836c",
   "metadata": {},
   "source": [
    "#### Clustering our data\n",
    "Instead of \"eyeballing\" as we did at first, what if we wanted to automatically sort the two different directions into two different groups? How would we most easily do that? We don't really want to have to _train_ this dataset as we don't really care which group is which in this case, we just want some way of splitting the data into sensible groups. As such we might want to use some kind of _unsupervised_ machine learning process.\n",
    "\n",
    "The **scikit-learn** package has a module called **sklearn.cluster** that allows us to solve this problem. There are many algorithms for different 'shapes' of clusters. Let's try converting our data into a format **scikit-learn** understands, then use the **Kmeans** clustering algorithm on them.\n",
    "\n",
    "Remember from Lecture 16, that **scikit-learn** requires our data to be in a format in which  each datapoint has a set of _features_ which are a bit like coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f0f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=np.array([poles_data.Pole_Az,poles_data.Pole_Plunge]).T\n",
    "print(input_data[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38f57e",
   "metadata": {},
   "source": [
    "Now let's do the clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e581fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = sklearn.cluster.KMeans(n_clusters=2) #This tells us that we are using a clustering algorithm with 2 clusters\n",
    "\n",
    "fit=kmeans.fit(input_data) #Fits the kmeans algorithm to our input data\n",
    "clusternumbers=kmeans.predict(input_data) #Gives the cluster numbers for each of our clusters\n",
    "#Plots the equal area with colors for clusters\n",
    "plot_equal_area(poles_data.Pole_Az,poles_data.Pole_Plunge,colors=clusternumbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10019494",
   "metadata": {},
   "source": [
    "Hmm, it seems like this didn't work exactly as expected. Notice how there seems to be a change in cluster across the 0 degree Azimuth line? Let's plot Azimuth against plunge on an x,y plot to see why this didn't seem to work very well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b9c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(poles_data.Pole_Az,poles_data.Pole_Plunge,c=clusternumbers,cmap='RdBu');\n",
    "plt.xlabel('Azimuth')\n",
    "plt.ylabel('Plunge');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53769757",
   "metadata": {},
   "source": [
    "The **Kmeans** algorithm treats data as if they were cartesian. But in geology, we often use directions that go from 0 to 360 which doesn't behave the same way as other cartesian data sets.  For example,an azimuth of 340 is closer to 200 than to 0 under this scheme. A simple solution to this would be to convert our azimuths and plunges to cartesian coordinates (as we did for the quiver plot) before clustering. Let's try again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983bb834",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = sklearn.cluster.KMeans(n_clusters=2) #This tells us that we are using a clustering algorithm \n",
    "# with 2 clusters\n",
    "input_data=np.array([u,v,w]).transpose() # make and array with u,v,w as the first, second and third rows\n",
    "fit=kmeans.fit(input_data) #Fits the kmeans algorithm to our input data\n",
    "clusternumbers=kmeans.predict(input_data) #Gives the cluster numbers for each of our clusters\n",
    "#Plots the equal area with colors for clusters\n",
    "plot_equal_area(poles_data.Pole_Az,poles_data.Pole_Plunge,colors=clusternumbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c230848f",
   "metadata": {},
   "source": [
    "Much better! Let's see how it looks on the satellite image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = [-115.7115, -115.6795, 33.5442, 33.5651]\n",
    "img = plt.imread(fpath+'Figures/GoogleEarthImage.png')\n",
    "plt.figure(figsize=(9,13))\n",
    "plt.imshow(img, origin='upper', extent=extent)\n",
    "plt.quiver(poles_data.Lon,poles_data.Lat,u,v,clusternumbers,cmap='RdBu'); #5th argument controls arrow color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d584fd5",
   "metadata": {},
   "source": [
    "Really cool.  It seems that there's something a bit more complicated going on here than just a single fold axis going down the middle, but we can see the broad trend and could probably even draw the axis in a lot of places now.\n",
    "One final thing to note with **Kmeans**; you are not required  to choose the number of clusters.  However letting it work on its own generally doesn't work too well as it will try to find clusters with very similar sizes. If we try it with this example, we get a lot of clusters which don't really tell us much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f9c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = sklearn.cluster.KMeans() #unspecified number of clusters\n",
    "input_data=np.array([u,v,w]).transpose()\n",
    "fit=kmeans.fit(input_data) #Fits the kmeans algorithm to our input data\n",
    "clusternumbers=kmeans.predict(input_data) #Gives the cluster numbers for each of our clusters\n",
    "#Plots the equal area with colors for clusters\n",
    "plot_equal_area(poles_data.Pole_Az,poles_data.Pole_Plunge,colors=clusternumbers,cmap='Accent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad844e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = [-115.7115, -115.6795, 33.5442, 33.5651]\n",
    "img = plt.imread(fpath+'Figures/GoogleEarthImage.png')\n",
    "plt.figure(figsize=(9,13))\n",
    "plt.imshow(img, origin='upper', extent=extent)\n",
    "plt.quiver(poles_data.Lon,poles_data.Lat,u,v,clusternumbers,cmap='Accent');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2431ac",
   "metadata": {},
   "source": [
    "# Searching for the global minimum\n",
    "\n",
    "Here we will try out some different approaches to find the global minimum for challenging equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef33c9",
   "metadata": {},
   "source": [
    "### Rosenbrock function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frb = lambda x: (x[0]-1)**2 + 100*(x[1]-x[0]**2)**2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure \n",
    "fig = plt.figure(figsize=(12, 7))\n",
    "ax = fig.subplots(1,1)\n",
    "\n",
    "# Evaluate function\n",
    "X = np.linspace(-2, 2, 100)\n",
    "Y = np.linspace(-1, 3, 100)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = frb([X,Y])\n",
    "\n",
    "# Plot the surface\n",
    "surf = ax.contourf(X,Y,np.log10(Z),cmap=plt.cm.turbo,levels=100)\n",
    "ax.contour(X,Y,np.log10(Z),colors='k',levels=np.arange(0,2+1e-5,0.5))\n",
    "# ax.set_zlim(0, 200)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=10,label='log10(Z)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122039e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frb([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0542545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple minimization\n",
    "res = sp.optimize.minimize(frb,[0,0])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c17c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sp.optimize.dual_annealing(frb,bounds=[[-5,5],[-5,5]])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795acd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sp.optimize.shgo(frb,bounds=[[-5,5],[-5,5]])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3a77f",
   "metadata": {},
   "source": [
    "### Ackley Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98361ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fack = lambda x: -20*np.exp(-0.2*np.sqrt(0.5*((x[0])**2+(x[1])**2)))-\\\n",
    "                np.exp(0.5*(np.cos(2*np.pi*(x[0]))+np.cos(2*np.pi*(x[1]))))+np.e+20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b6bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fack([0,0]),fack([3,3]),fack([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2cde68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure \n",
    "fig = plt.figure(figsize=(12, 7))\n",
    "ax = fig.subplots(1,1)\n",
    "\n",
    "# Evaluate function\n",
    "X = np.linspace(-5, 5, 100)\n",
    "Y = np.linspace(-5, 5, 100)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = fack([X,Y])\n",
    "\n",
    "# Plot the surface\n",
    "surf = ax.contourf(X,Y,Z,cmap=plt.cm.turbo,levels=100)\n",
    "ax.contour(X,Y,np.log10(Z),colors='k',levels=np.arange(0,2+1e-5,0.5))\n",
    "# ax.set_zlim(0, 200)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sp.optimize.minimize(fack,[3,3])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 7))\n",
    "ax = fig.subplots(1,1)\n",
    "# Plot the surface\n",
    "surf = ax.contourf(X,Y,Z,cmap=plt.cm.turbo,levels=100)\n",
    "ax.contour(X,Y,np.log10(Z),colors='k',levels=np.arange(0,2+1e-5,0.5))\n",
    "ax.plot(res.x[0],res.x[1],'s',color='white',mec='grey',markersize=10)\n",
    "# ax.set_zlim(0, 200)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f08d9d",
   "metadata": {},
   "source": [
    "Well that's not right. What happens if we try again, with randomly seeded first guesses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndraw = 100\n",
    "resx = np.array([sp.optimize.minimize(fack,rr).x for rr in np.random.uniform(-5,5,size=(ndraw,2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d9ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 7))\n",
    "ax = fig.subplots(1,1)\n",
    "# Plot the surface\n",
    "surf = ax.contourf(X,Y,Z,cmap=plt.cm.turbo,levels=100)\n",
    "ax.contour(X,Y,np.log10(Z),colors='k',levels=np.arange(0,2+1e-5,0.5))\n",
    "ax.plot(resx[:,0],resx[:,1],'s',color='white',mec='grey',markersize=10)\n",
    "# ax.set_zlim(0, 200)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdd8481",
   "metadata": {},
   "source": [
    "Still not looking good. Bigger numbers go brrrr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa39a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndraw = 2500\n",
    "resx = np.array([sp.optimize.minimize(fack,rr).x for rr in np.random.uniform(-5,5,size=(ndraw,2))])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 7))\n",
    "ax = fig.subplots(1,1)\n",
    "# Plot the surface\n",
    "surf = ax.contourf(X,Y,Z,cmap=plt.cm.turbo,levels=100)\n",
    "ax.contour(X,Y,np.log10(Z),colors='k',levels=np.arange(0,2+1e-5,0.5))\n",
    "ax.plot(resx[:,0],resx[:,1],'o',color='white',mec='grey',markersize=5)\n",
    "# ax.set_zlim(0, 200)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129adf4",
   "metadata": {},
   "source": [
    "Well now I'm more lost than ever. Still, let's check the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7eeb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a square Figure.\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "# Add a gridspec with two rows and two columns and a ratio of 1 to 4 between\n",
    "# the size of the marginal axes and the main axes in both directions.\n",
    "# Also adjust the subplot parameters for a square plot.\n",
    "gs = fig.add_gridspec(2, 2,  width_ratios=(4, 1), height_ratios=(1, 4),\n",
    "                      left=0.1, right=0.9, bottom=0.1, top=0.9,\n",
    "                      wspace=0.05, hspace=0.05)\n",
    "# Create the Axes.\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "ax_histx = fig.add_subplot(gs[0, 0], sharex=ax)\n",
    "ax_histy = fig.add_subplot(gs[1, 1], sharey=ax)\n",
    "\n",
    "    # no labels\n",
    "ax_histx.tick_params(axis=\"x\", labelbottom=False)\n",
    "ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "\n",
    "# the scatter plot:\n",
    "ha = ax.hist2d(x=resx[:,0],y=resx[:,1],cmap=plt.cm.BuPu,bins=np.arange(-5.5,5.6,1));\n",
    "\n",
    "ax_histx.hist(resx[:,0], bins=np.arange(-5.5,5.6,1),edgecolor='k');\n",
    "ax_histy.hist(resx[:,1], bins=np.arange(-5.5,5.6,1), orientation='horizontal',edgecolor='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13ab652",
   "metadata": {},
   "source": [
    "Okay so it works with a Monte Carlo, but there's got to be a smarter way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c30d49",
   "metadata": {},
   "source": [
    "## Annealing\n",
    "\n",
    "Xiang, Y., Sun, D.Y., Fan, W. and Gong, X.G., 1997. Generalized simulated annealing algorithm and its application to the Thomson model. Physics Letters A, 233(3), pp.216-220.\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S037596019700474X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec732916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = sp.optimize.dual_annealing(fack,bounds=[[-5,5],[-5,5]])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26f2982",
   "metadata": {},
   "source": [
    "# SHGO\n",
    "Endres, SC, Sandrock, C, Focke, WW (2018) “A simplicial homology algorithm for lipschitz optimisation”, Journal of Global Optimization.\n",
    "https://link.springer.com/article/10.1007/s10898-018-0645-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a5207",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sp.optimize.shgo(fack,bounds=[[-5,5],[-5,5]])\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
